# Step 1: Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

# Step 2: Create a dataset (non-linear relationship)
X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([3, 6, 11, 18, 27, 38, 51, 66, 83, 102])

# Convert to DataFrame (optional – for analysis)
df = pd.DataFrame({'X': X.flatten(), 'y': y})

# Step 3: Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 4: Apply Polynomial Features (degree = 2)
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Step 5: Train the Polynomial Regression model
model = LinearRegression()
model.fit(X_train_poly, y_train)

# Step 6: Make predictions
y_pred = model.predict(X_test_poly)

# Step 7: Evaluate the model performance
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\n--- Model Performance ---")
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("R-squared (R² Score):", r2)

# Step 8: Visualize the Polynomial Regression curve
X_range = np.linspace(min(X), max(X), 100).reshape(-1, 1)
X_range_poly = poly.transform(X_range)
y_range_pred = model.predict(X_range_poly)

plt.scatter(X, y, label="Actual Data")
plt.plot(X_range, y_range_pred, label="Polynomial Regression Curve")
plt.xlabel("X")
plt.ylabel("y")
plt.title("Polynomial Regression (Degree = 2)")
plt.legend()
plt.show()
